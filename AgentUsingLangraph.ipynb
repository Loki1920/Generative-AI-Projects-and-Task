{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrTTQ2cnD7DP",
        "outputId": "c24cd8e8-aa62-42b5-deb2-5f65231837d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<0.3,>=0.2.27 (from langgraph)\n",
            "  Downloading langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-1.0.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.107-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m354.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langgraph-0.2.14-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.36-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_checkpoint-1.0.6-py3-none-any.whl (15 kB)\n",
            "Downloading langsmith-0.1.107-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.15 langchain-core-0.2.36 langchain-openai-0.1.23 langchain-text-splitters-0.2.2 langgraph-0.2.14 langgraph-checkpoint-1.0.6 langsmith-0.1.107 openai-1.43.0 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rep4YLNOEb8j",
        "outputId": "bf3bbb12-3c4b-434d-c1f1-43c5830ca584"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.15 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.15)\n",
            "Requirement already satisfied: langchain-core==0.2.36 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.36)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.107)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.15->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.36->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core==0.2.36->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core==0.2.36->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.2.14-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.14 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Agent"
      ],
      "metadata": {
        "id": "vU4YkfciKGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Creating the first analysis agent to check the prompt structure\n",
        "# This print part helps you to trace the graph decisions\n",
        "def analyze_question(state):\n",
        "    llm = ChatOpenAI()\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are an agent that needs to define if a question is a technical code one or a general one.\n",
        "\n",
        "    Question : {input}\n",
        "\n",
        "    Analyse the question. Only answer with \"code\" if the question is about technical development. If not just answer \"general\".\n",
        "\n",
        "    Your answer (code/general) :\n",
        "    \"\"\")\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\"input\": state[\"input\"]})\n",
        "    decision = response.content.strip().lower()\n",
        "    return {\"decision\": decision, \"input\": state[\"input\"]}\n",
        "\n",
        "# Creating the code agent that could be way more technical\n",
        "def answer_code_question(state):\n",
        "    llm = ChatOpenAI()\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"You are a software engineer. Answer this question with step by steps details : {input}\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\"input\": state[\"input\"]})\n",
        "    return {\"output\": response}\n",
        "\n",
        "# Creating the generic agent\n",
        "def answer_generic_question(state):\n",
        "    llm = ChatOpenAI()\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"Give a general and concise answer to the question: {input}\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\"input\": state[\"input\"]})\n",
        "    return {\"output\": response}"
      ],
      "metadata": {
        "id": "N3uweMXOEH1P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the graph"
      ],
      "metadata": {
        "id": "BrRgiNr0KW-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import Annotated, TypedDict\n",
        "#from agents import analyze_question, answer_code_question, answer_generic_question\n",
        "\n",
        "#You can precise the format here which could be helpfull for multimodal graphs\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    output: str\n",
        "    decision: str\n",
        "\n",
        "#Here is a simple 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
        "def create_graph():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    workflow.add_node(\"analyze\", analyze_question)\n",
        "    workflow.add_node(\"code_agent\", answer_code_question)\n",
        "    workflow.add_node(\"generic_agent\", answer_generic_question)\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"analyze\",\n",
        "        lambda x: x[\"decision\"],\n",
        "        {\n",
        "            \"code\": \"code_agent\",\n",
        "            \"general\": \"generic_agent\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.set_entry_point(\"analyze\")\n",
        "    workflow.add_edge(\"code_agent\", END)\n",
        "    workflow.add_edge(\"generic_agent\", END)\n",
        "\n",
        "    return workflow.compile()\n"
      ],
      "metadata": {
        "id": "TeZJ9Pc8EisU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Launching the program"
      ],
      "metadata": {
        "id": "4Pa3-d01KdoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Embedding API keys directly in your code is definilty not secure or recommended for production environments.\n",
        "#Always use proper key management practices.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "#from graph import create_graph\n",
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "class UserInput(TypedDict):\n",
        "    input: str\n",
        "    continue_conversation: bool\n",
        "\n",
        "def get_user_input(state: UserInput) -> UserInput:\n",
        "    user_input = input(\"\\nEnter your question (ou 'q' to quit) : \")\n",
        "    return {\n",
        "        \"input\": user_input,\n",
        "        \"continue_conversation\": user_input.lower() != 'q'\n",
        "    }\n",
        "\n",
        "def process_question(state: UserInput):\n",
        "    graph = create_graph()\n",
        "    result = graph.invoke({\"input\": state[\"input\"]})\n",
        "    print(\"\\n--- Final answer ---\")\n",
        "    print(result[\"output\"])\n",
        "    return state\n",
        "\n",
        "def create_conversation_graph():\n",
        "    workflow = StateGraph(UserInput)\n",
        "\n",
        "    workflow.add_node(\"get_input\", get_user_input)\n",
        "    workflow.add_node(\"process_question\", process_question)\n",
        "\n",
        "    workflow.set_entry_point(\"get_input\")\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"get_input\",\n",
        "        lambda x: \"continue\" if x[\"continue_conversation\"] else \"end\",\n",
        "        {\n",
        "            \"continue\": \"process_question\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_edge(\"process_question\", \"get_input\")\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "def main():\n",
        "    conversation_graph = create_conversation_graph()\n",
        "    conversation_graph.invoke({\"input\": \"\", \"continue_conversation\": True})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGCjqFxgGVal",
        "outputId": "d863d7b3-8b24-4960-cf41-ad7162b432b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your question (ou 'q' to quit) : What are the benefits of a balanced diet?\n",
            "\n",
            "--- Final answer ---\n",
            "content='A balanced diet provides essential nutrients, helps maintain a healthy weight, boosts energy levels, improves overall health, and reduces the risk of chronic diseases.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 26, 'total_tokens': 55}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-74e3eec1-0eda-48c7-9d51-3b0b9651807a-0' usage_metadata={'input_tokens': 26, 'output_tokens': 29, 'total_tokens': 55}\n",
            "\n",
            "Enter your question (ou 'q' to quit) : What is the difference between a list and a tuple in Python\n",
            "\n",
            "--- Final answer ---\n",
            "content='In Python, both lists and tuples are used to store multiple items in a single variable, but there are some key differences between the two:\\n\\n1. Mutability:\\n- Lists are mutable, which means that you can change, add, or remove elements from a list after it has been created.\\n- Tuples, on the other hand, are immutable, which means that once a tuple is created, you cannot change its elements.\\n\\n2. Syntax:\\n- Lists are defined using square brackets [ ] and elements are separated by commas.\\n- Tuples are defined using parentheses ( ) and elements are separated by commas.\\n\\n3. Performance:\\n- Tuples are generally more efficient than lists in terms of both memory and performance because tuples are immutable and their size cannot change.\\n- Lists, being mutable, require more memory and processing power to manage changes to their elements.\\n\\nHere is an example to illustrate the difference between a list and a tuple in Python:\\n\\n```python\\n# List example\\nmy_list = [1, 2, 3]\\nprint(my_list)\\nmy_list.append(4)\\nprint(my_list)\\n\\n# Tuple example\\nmy_tuple = (1, 2, 3)\\nprint(my_tuple)\\n# This will raise an error because tuples are immutable\\n# my_tuple.append(4)\\n```\\n\\nIn summary, lists are more flexible but less efficient, while tuples are more efficient but less flexible. Depending on your requirements, you can choose between lists and tuples in Python.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 34, 'total_tokens': 330}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-8ea6e3a0-a1d9-4175-b6e4-6e0615281639-0' usage_metadata={'input_tokens': 34, 'output_tokens': 296, 'total_tokens': 330}\n",
            "\n",
            "Enter your question (ou 'q' to quit) : asdfghjkl\n",
            "\n",
            "--- Final answer ---\n",
            "content='There is no specific meaning or answer to the string of letters \"asdfghjkl.\" It is often used as a random sequence of characters to express frustration or confusion.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 22, 'total_tokens': 56}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-61da3e99-ce72-438c-9349-cbb7c1b9f239-0' usage_metadata={'input_tokens': 22, 'output_tokens': 34, 'total_tokens': 56}\n",
            "\n",
            "Enter your question (ou 'q' to quit) : what is stock market\n",
            "\n",
            "--- Final answer ---\n",
            "content='The stock market is a public market where individuals and institutions trade shares of companies, allowing investors to buy and sell ownership in publicly traded companies.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9f78e5fa-ec2a-4646-bac5-9b1d0fb54d19-0' usage_metadata={'input_tokens': 21, 'output_tokens': 28, 'total_tokens': 49}\n",
            "\n",
            "Enter your question (ou 'q' to quit) : what is stock market , how we can use python programming language to analyse the stock ?\n",
            "\n",
            "--- Final answer ---\n",
            "content=\"The stock market is a place where shares of publicly traded companies are bought and sold. These shares represent ownership in a company and can be bought and sold by investors to potentially earn a profit. Stock prices are influenced by a variety of factors such as company performance, economic conditions, and market trends.\\n\\nTo analyze stocks using Python programming language, follow these steps:\\n\\n1. Data Collection: The first step is to collect historical stock price data. There are several ways to do this, including using APIs provided by financial data providers such as Alpha Vantage, Yahoo Finance, or Quandl.\\n\\n2. Data Processing: Once you have collected the data, you need to process it to make it usable for analysis. This may involve cleaning the data, removing any missing values, and formatting it in a way that is suitable for analysis.\\n\\n3. Data Visualization: Python has several libraries such as Matplotlib and Seaborn that can be used to create visualizations of the stock price data. Visualizations can help in identifying trends and patterns in the data.\\n\\n4. Statistical Analysis: Python also has libraries such as NumPy and Pandas that can be used to perform statistical analysis on the stock price data. This may involve calculating moving averages, volatility, and other metrics to better understand the stock's performance.\\n\\n5. Machine Learning: Python has libraries such as Scikit-learn that can be used to build machine learning models to predict stock prices. These models can be trained on historical data and used to make predictions about future stock price movements.\\n\\nBy following these steps, you can use Python programming language to analyze stocks and make informed investment decisions in the stock market.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 330, 'prompt_tokens': 39, 'total_tokens': 369}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-86dab946-f21b-43e4-9fb8-f6e94d724729-0' usage_metadata={'input_tokens': 39, 'output_tokens': 330, 'total_tokens': 369}\n",
            "\n",
            "Enter your question (ou 'q' to quit) : q\n"
          ]
        }
      ]
    }
  ]
}